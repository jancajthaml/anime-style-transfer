\chapter{Framework's user guide}

The framework was build around Girshick's Python implementation of Faster \rcnn~\cite{faster}, found at \url{https://github.com/rbgirshick/py-faster-rcnn} and is entirely written in Python as well. The framework depends on lxml, NumPy and matplotlib libraries and on Caffe~\cite{caffe} library which is distributed with Python implementation of Faster \rcnn{}. The framework's code can be found at \url{https://gitlab.fel.cvut.cz/students/jasek-otakar}.

\section{Evaluation framework}
The whole framework consists of three main programs and 5 supportive ones. The programs are:
\begin{itemize}
\item Main programs
\begin{itemize}
\item \hyperref[rec]{\pyarg{recognize.py}}
\item \hyperref[pr]{\pyarg{precision\_recall.py}}
\item \hyperref[tr]{\pyarg{train.py}}
\end{itemize}
\item Supportive programs
\begin{itemize}
\item \hyperref[ftf]{\pyarg{faster\_to\_folder.py}}
\item \hyperref[bbox]{\pyarg{victims\_bbox.py}}
\item \hyperref[xtk]{\pyarg{xml\_to\_kitti.py}}
\item \hyperref[ktx]{\pyarg{kitti\_to\_xml.py}}
\item \hyperref[tme]{\pyarg{time.py}}
\end{itemize}
\item Configuration and miscellaneous python files and modules
\begin{itemize}
\item \hyperref[xml]{\pyarg{xmldb.py}}
\item \hyperref[init]{\pyarg{\_init\_paths.py}}
\item \hyperref[parse]{\pyarg{help\_parser.py}}
\end{itemize}
\end{itemize}

In the following sections we will briefly describe all the programs. All of the positional arguments are specified in place of such argument, all of the optional arguments (the ones starting with \texttt{-}) must have the argument name preceding. All of the standalone programs using argument parser also take argument \pyarg{-h}, which prints the usual help.

\subsection{\pyarg{recognize.py}} \label{rec}
Program \pyarg{recognize.py} is the core tool of the whole evaluation framework. \pyarg{recognize.py} reads visual data in either form of folder with images or video file and produces XML file with detection and recognition data. For proper functioning you have to set \pyarg{py-faster-rcnn} root dir and \pyarg{MODEL\_DIR} in \hyperref[init]{\pyarg{\_init\_paths.py}}.

The program \pyarg{recognize.py} has 15 arguments, one of them is required.
\begin{description}
\descitem{input} Argument specifying input -- could be either a folder with images and videos or a video file. If the input is video file or a folder contains a video file, then video is processed frame by frame.
\descitem{-folder} Optional argument, indicating folder to save output images (if boolean argument \pyarg{-nv} is not specified). If it is not set, input folder is used. If visual output is desired, at least one of \pyarg{-folder} and \pyarg{-prefix} must be specified.
\descitem{-prefix} Prefix of saved output images. If it is not set, empty string is used. If visual output is desired, at least one of \pyarg{-folder} and \pyarg{-prefix} must be specified.
\descitem{-t} Measuring time of each detection and saving it to XML file. This argument is boolean.
\descitem{-ox} Name of output XML file. If the file already exists, it will be overwritten. If this argument is not specified, output will be written to stdout.
\descitem{-gpu} ID of GPU device on the system to use. Default value is 0.
\descitem{-cpu} CPU only mode. This argument is boolean, if it is set, it overrides \pyarg{-gpu} option. Note that this will make whole process considerably slower.
\descitem{-net} Network architecture and weights to use. Currently only VGG16~\cite{vgg16} and ZFNet~\cite{zfnet} are supported, both with plugged RPN unit. Choices are determined by contents of the folder \pyarg{MODEL\_DIR} specified in \hyperref[init]{\pyarg{\_init\_paths.py}}. Two networks originating from \cite{faster} are saved in folders \pyarg{vgg16\_orig} and \pyarg{zf\_orig}, pretrained on a training subset of VOC2007\cite{voc2007} dataset. Default value is \pyarg{vgg16\_orig}.
\descitem{-conf} Minimum confidence level on detection needed to record the data. Default value is 0.8.
\descitem{-move} Maximum movement of object (on each side of bounding box) within two frames to be recorded as the same object expressed as percentage of the image dimensions. This option applies only to video files processed. Default value is 0.02.
\descitem{-nms} Minimum threshold for Non-Maximum Suppression (NMS) overlap expressed as percentage to merge two detections. Default value is 0.3
\descitem{-box} Show infobox with class and confidence above detected class in output images. Applies only if visual output is desired.
\descitem{-nv} Boolean argument, setting visual output to false (short for 'no visuals'). If set, arguments \pyarg{-folder}, \pyarg{-prefix} and \pyarg{-box} do not apply.
\descitem{-vaf} Treat videos as folders. When this argument is specified, resulting XML files will contain the same information for video files as they would for folders, therefore no merging of same objects within different frames of video files will be done. Tag \xtag{object} will then contain information about a frame in which object was detected. This argument is boolean.
\descitem{-v} Verbose mode. This argument is boolean.
\end{description}

The order of arguments does not matter since there is only one positional argument and the rest of them are optional. However, it is considered a good practice to always have a positional argument either first or last, but never in the middle.

\begin{usage}
recognize.py [-folder FOLDER] [-prefix PREFIX] [-ox OUTPUT_XML] [-t] [-gpu GPU_ID] [-cpu] [-net {vgg16,zf}] [-conf CONF] [-move MOVE] [-nms NMS] [-box] [-nv] [-vaf] [-v] input
\end{usage}

\subsection{\pyarg{precision\_recall.py}} \label{pr}
Program \pyarg{precision\_recall.py} is a tool for plotting precision-recall curves out of specified XML files containing ground truth information and prediction files outputted by \hyperref[rec]{\pyarg{recognize.py}} tool. This tool works only on files from running \pyarg{recognize.py} tool in 'folder' mode (therefore it cannot be used on single video file). Note that this tool works without running graphical server since \pyarg{matplotlib} is called with \pyarg{Agg} backend.

This tool takes 6 arguments. Due to the fact that you cannot specify more than one required argument to take a form of list, list arguments \pyarg{-gt} and \pyarg{-pred} are listed as optional, however they can be seen as required since without them, the program has no data to operate on.
\begin{description}
\descitem{out} Output file for a plot. If no extension specifying the format of desired plot is given, EPS file format will be used.
\descitem{-gt} List of ground truth files in XML format. Note that this argument takes a list, therefore you cannot use \pyarg{-} as a prefix in any of the files, as this would end the argument sequence. List is terminated by either end of parameter string or a next parameter started by \pyarg{-}, therefore this argument cannot appear before \pyarg{out} argument.
\descitem{-pred} List of prediction files in XML format outputted by \pyarg{recognize.py} tool. The same constraints on a list apply as in \pyarg{-gt}.
\descitem{-bins} Number of bins to use for different confidence levels. Default value is 41. Note that higher values will lead to higher computation time.
\descitem{-over} Overlap ratio of bounding boxes for determining whether the prediction was correct. Default value is 0.5.
\descitem{-cls} Compute separate statistics for distinct classes. Note that when this argument is specified, it takes a significantly larger amount of time to process large datasets with mode classes. This argument is boolean.
\descitem{-v} Verbose mode. This argument is boolean.
\end{description}

\begin{usage}
precision_recall.py [-gt GT [GT ...]] [-pred PRED [PRED ...]] [-bins NUM_BINS] [-over OVER] [-data DATA] [-cls] [-v] out
\end{usage}

\subsection{\pyarg{train.py}} \label{tr}
Program \pyarg{train.py} allows you to train a network from your ground truth XML files. The tool itself expects a base model specified by the same conventions as argument \pyarg{-net} in \hyperref[rec]{\pyarg{recognize.py}} tool.

The tool takes 11 arguments, three of them are required.
\begin{description}
\descitem{use\_net} Base network model to be used for training. This argument can take same arguments as argument \pyarg{-net} in \pyarg{recognize.py} tool, however, it is recommended to train only on original networks, i.e. \pyarg{vgg16\_orig} and \pyarg{zf\_orig}.
\descitem{out} Specifies directory in which the trained network will be saved. This directory will have same structure as other directories in \pyarg{MODEL\_DIR}, therefore you do not have to do any meddling with files and immediately start using it by \pyarg{recognize.py} tool.
\descitem{xml} List of XML files containing ground truth information about training dataset. Note that this argument takes a list of values, therefore it has to be terminated by either end of arguments or start of any positional argument.
\descitem{-cache} Whether to use cache to preload training dataset. This argument is a boolean argument.
\descitem{-gpu} ID of GPU device on the system to use. Default value is 0.
\descitem{-solver} Use different solver than the one used by base model. More information about this can be found at Caffe~\cite{caffe} documentation pages.
\descitem{-iters} Maximum number of iterations used by solver. Default value is 4000.
\descitem{-cfg} Use additional config file to override default Caffe and Faster \rcnn configuration. The configuration files are stored in YAML file format, however default setting is sufficient enough.
\descitem{-rand} Do not use predefined randomization seeds and randomize the whole process of training. This argument is boolean.
\descitem{-keep\_int} Keep intermediate models. Note, that default snapshotting frequency of a solver is set to 10000, so you need to overwrite this value by custom config file if using default number of iterations to actually get any intermediate snapshots. This argument is boolean.
\descitem{-nf} Do not use flipped images for training. This argument is boolean.
\end{description}

\begin{usage}
train.py use_net out xml [xml ...] [-cache] [-gpu GPU] [-solver SOLVER] [-iters MAX_ITERS] [-cfg CFG] [-rand] [-keep_int] [-nf]
\end{usage}

\subsection{\pyarg{faster\_to\_folder.py}} \label{ftf}
\pyarg{faster\_to\_folder.py} is a simple tool to help visualising and analysing data. Its main purpose is to take a XML file outputted by \hyperref[rec]{\pyarg{recognize.py}} and copy all outputted images from one class to one folder to easily examine all images labeled as i.e. class 'bottle'. It also creates a special folder for images in which were no classes detected.

This tool takes only two arguments:
\begin{description}
\descitem{xml} Name of XML file to be used as a detection data.
\descitem{-dir} Root directory of folder structure created by copying files to folders by class. If not specified, default value is the folder of XML file.
\end{description}

\begin{usage}
faster_to_folder.py [-dir DIR] xml
\end{usage}

\subsection{\pyarg{victims\_bbox.py}} \label{bbox}
This is a simple tool creating ground truth files (with bounding boxes) from binary segmented images where each pixel is denoted by either 1 or 0, depending on whether the said pixel contains an object or not. By default fills all objects with class \pyarg{person}. This behavior can be changed by argument \pyarg{-cls}

This tool takes 3 positional arguments and 2 optional arguments.
\begin{description}
\descitem{dir} Input directory containing only mask images for victim datasets.
\descitem{datadir} Directory, where original files reside. Important for being able to match ground truth and prediction files correctly.
\descitem{xml} Outputted XML file in ground truth format (attribute \pyarg{conf} is filled with value \pyarg{'gt'} standing for ground truth, root element of resulting XML is \xtag{Ground\_truth}).
\descitem{-cls} String to fill as a class for encountered objects. Default is \pyarg{person}.
\descitem{-name} Name of dataset to use in resulting XML file. Default is \pyarg{Victims}.
\end{description}
 
\begin{usage}
victims_bbox.py dir datadir xml [-cls CLS] [-name NAME]
\end{usage}

\subsection{\pyarg{xml\_to\_kitti.py}} \label{xtk}
This tool is used for transformation of our XML format to KITTI~\cite{kitti} data format. Currently it maps only classes \{car, person, bycicle\} to KITTI classes \{Car, Pedestrian, Cyclist\} as those are only three classes used in KITTI evaluation tool.

This tool takes three arguments, two of them are positional
\begin{description}
\descitem{xml} Input XML file containing prediction information. Note that this file could be created only from \hyperref[rec]{\pyarg{recognize.py}} tool running in 'folder' mode.
\descitem{dir} Output directory to store KITTI data files. Note that all values that are missing from KITTI file format (occlusion, rotation, etc.) will be filled to 0. This does not bother KITTI evaluation tool if it is evaluating only object detection and recognition.
\descitem{-v} Verbose mode. This argument is boolean argument.
\end{description}

\begin{usage}
xml_to_kitti.py [-v] xml dir
\end{usage}

\subsection{\pyarg{kitti\_to\_xml.py}} \label{ktx}
This tool does reverse conversion of \hyperref[xtk]{\pyarg{xml\_to\_kitti.py}}. As \pyarg{xml\_to\_kitti.py}, it maps only KITTI classes \{Car, Pedestrian, Cyclist\} to our classes \{car, person, bycicle\}.

This tool takes 5 arguments as opposed to \hyperref[xtk]{\pyarg{xml\_to\_kitti.py}}, two of them or positional.
\begin{description}
\descitem{dir} Input directory with KITTI data files.
\descitem{xml} Output XML file containing prediction information. This file is formatted as from \hyperref[rec]{\pyarg{recognize.py}} tool. If the KITTI data files are ground truth labels (they do not contain probability score), it treats them as such.
\descitem{-im\_dir} Image directory to be used in XML file. Note that this directory is usually different from the directory where the label files are stored. Default value is input directory.
\descitem{-im\_ext} Image extension to be used in XML file. Default value is jpg.
\descitem{-v} Verbose mode. This argument is boolean argument.
\end{description}

\begin{usage}
kitti_to_xml.py [-im_dir IM_DIR] [-im_ext IM_EXT] [-v] folder xml
\end{usage}

\subsection{\pyarg{time.py}} \label{tme}
This simple tool only takes timing data from XML files produced by \hyperref[rec]{\pyarg{recognize.py}} and outputs average, minimal and maximal time in seconds. It takes only one argument in a form of a list.

\begin{description}
\descitem{data} List of XML files from \hyperref[rec]{\pyarg{recognize.py}}.
\end{description}

\begin{usage}
time.py data [data ...]
\end{usage}

\subsection{\pyarg{xmldb.py}} \label{xml}
Module \pyarg{xmldb.py} contains only one class named xmldb, which is extension of class imdb from \pyarg{datasets.imdb} from original Faster \rcnn framework and is used for training. You can specify custom \pyarg{CACHE\_DIR} where to store caches of loaded xmldb objects. In the most simple situation you need to initialize it only by a list of XML files passed as first argument to \pyarg{\_\_init\_\_} method and the class takes care of the rest of setting up. However it might be desirable to use different classes than the ones from VOC datasets -- then you can do so by specifying argument \pyarg{clazz}.

\subsection{\pyarg{\_init\_paths.py}} \label{init}
In this module, you need to set two configuration paths in order for tool \hyperref[rec]{\pyarg{recognize.py}} to work properly. It essentially import paths of Caffe~\cite{caffe} and Python Faster \rcnn bindings to \pyarg{PYTHONPATH} for you to be able to import them later.

\begin{description}
\descitem{INSTALL\_PATH} Root directory of your installation of \pyarg{py-faster-rcnn}.
\descitem{MODEL\_DIR} If you need to move pretrained Faster \rcnn models to a custom directory, specify such directory in this variable. You are not able to use default \pyarg{MODEL\_DIR} used by Faster \rcnn, since this framework uses slightly different file structure than the original Faster \rcnn framework. The directory structure of \pyarg{MODEL\_DIR} is briefly described in section \ref{models}
\end{description}

\subsection{\pyarg{help\_parser.py}} \label{parse}
This simple module just redefines \pyarg{error} method of original ArgumentParser from module \pyarg{argparse} to print help on error.

\subsection{XML format}

The most important tag of supported XML format is tag \xtag{file} which contains analysis of one file. The tag \xtag{file} can contain these attributes:

\begin{description}
\descitem{path} Full path of analysed file.
\descitem{newpath} Full path of visual representation of detection. Only applicable for prediction files when option \pyarg{-nv} was not set.
\descitem{time} Timing data of analysis of this particular image. Applicable only for prediction files if timing option \pyarg{-t} was set and only for image files. Timing is in seconds.
\descitem{avg\_time} Average time for a frame in a video file. Applicable only for prediction files ran on video when timing option \pyarg{-t} was set. Timing is in seconds.
\descitem{framecount} Number of frames of a video file.
\end{description}

The tag \xtag{file} contains tags \xtag{object} which represent either ground truth objects or objects detected by Faster \rcnn network. The tag \xtag{object} can contain these attributes:

\begin{description}
\descitem{class} Class of an object. Applicable for both image and video files.
\descitem{bbox} Bounding box of an object. Applicable for image files only. The bounding box is in format (top-left, top-right, bottom-left, bottom-right).
\descitem{prob} Confidence of detection, in range $(0,1)$. For ground truth files, string 'gt' is used instead. Applicable for image files only.
\end{description}

Following attributes are applicable only for video files.
\begin{description}
\descitem{first\_frame} Number of first frame where the object was detected.
\descitem{last\_frame} Number of the last frame where the same object was detected. The maximal allowed movement of an object within frames is determined by \pyarg{-move} in tool \hyperref[rec]{\pyarg{recognize.py}}.
\descitem{first\_bbox} Bounding box of an object in a first frame where the object was detected.
\descitem{last\_bbox} Bounding box of an object in a last frame where the object was detected.
\descitem{highest} Highest confidence in frames where the object was detected.
\descitem{lowest} Lowest confidence in frames where the object was detected.
\end{description}

The tag \xtag{file} can be a standalone, but more commonly is enclosed within a tag \xtag{folder}. Tag \xtag{folder} can contain these attributes:

\begin{description}
\descitem{path} Absolute path to a folder.
\descitem{files} Number of files in a folder.
\descitem{usable\_files} Number of analyzable files -- only image or video files. Applicable only for prediction files, all tools for ground truth files get number of files programmatically and therefore this number would be the same as files.
\end{description}

The root element of a XML file is customizable -- there is no strict rule what tag should you use. However, this tag with its attributes contains information about experiment. For prediction files we were using tag \xtag{Faster\_RCNN\_experiment} with attributes describing runtime parameters of \hyperref[rec]{\pyarg{recognize.py}} tool. Note, that attribute "time" is different than a sum of all attributes "time" of \xtag{file} tags. This is due to the fact, that this value measures whole time of a whole experiment while timing for a file measures only detection runtime without postprocessing. For ground truth files we were using tag \xtag{Ground\_truth} with one attribute specifying dataset.

\subsubsection{XML example}
As an example, we provide small portion of used XML file:

\begin{lstlisting}[numbers=left]
<?xml version="1.0" ?>
<Faster_RCNN_experiment conf="0.1" move="0.02" network="vgg16" nms="0.3" time="690.945771933" type="folder">
	<folder files="3" path="/path/to/folder" usable_files="2">
		<file path="/path/to/folder/img.png" time="0.6403028965">
			<object bbox="(132.91631, 282.65521, 524.46863, 461.32788)" class="person" prob="0.739661"/>
			<object bbox="(462.49478, 36.464203, 583.87549, 470.51736)" class="person" prob="0.20808"/>
		</file>
		<file path="/path/to/folder/vid.avi" framecount="10">
			<object class="car" first_bbox="(769.43323, 401.034, 901.0802, 477.86676)" first_frame="0" highest="0.995664" last_bbox="(767.76202, 408.27109, 899.92133, 475.68185)" last_frame="3" lowest="0.994525"/>
		</file>
	</folder>
</Faster_RCNN_experiment>
\end{lstlisting}

\subsection{\pyarg{MODEL\_DIR} structure} \label{models}
Our custom structure of \pyarg{MODEL\_DIR} contains one directory called \texttt{models} and then one directory for each model. Directory for each model of \texttt{<name>} contains caffemodel of name \texttt{<name>.caffemodel}, where the \texttt{<name>} is the same as directory name and a solver for testing (used by tool \hyperref[rec]{\pyarg{recognize.py}}) called \texttt{test.pt} and a symlink to corresponding train directory containing train solvers. Directory \texttt{models} contains training solvers and is the one where each particular model directory links to.
\newpage
Structure of \pyarg{MODEL\_DIR}:
\begin{lstlisting}[numbers=none]
MODEL_DIR
|- models
|  |- VGG16
|  |  \- end2end
|  |     |- solver.pt
|  |     \- train.pt
|  |
|  \- ZF
|     \- end2end
|        |- solver.pt
|        \-train.pt
|
|- vgg16_orig
|  |- test.pt
|  |- vgg16_orig.caffemodel
|  \- train -> MODEL_DIR/models/VGG16/
|
|- zf_orig
|  |- test.pt
|  |- zf_orig.caffemodel
|  \- train -> MODEL_DIR/model/ZF/
|
\- ...
\end{lstlisting}

\section{Usage example}

As an example, we provide series of commands used to train VGG16 network and obtain precision recall curves and intermediate data for victims dataset. Similar steps would be taken for ZFNet architecture or a different dataset.

\begin{lstlisting}[language=bash, numbers=left]
./victims_bbox.py $DATA/victims/mask/tst/ $DATA/victims/orig/tst/ ./tst_gt.xml
./victims_bbox.py $DATA/victims/mask/trn/ $DATA/victims/orig/tst/ ./trn_gt.xml
./victims_bbox.py $DATA/victims/mask/val/ $DATA/victims/orig/tst/ ./val_gt.xml

./train vgg16_orig vgg16_vict ./trn_gt.xml

./recognize.py $DATA/victims/orig/tst -ox ./tst_pred.xml -nv -conf 0.1 -net vgg16_vict -t
.recognize.py $DATA/victims/orig/trn -ox ./trn_pred.xml -nv -conf 0.1 -net vgg16_vict -t
./recognize.py $DATA/victims/orig/val -ox ./val_pred.xml -nv -conf 0.1 -net vgg16_vict -t

./precision_recall.py ./tst_pr.eps -pred ./tst_pred.xml -gt ./tst_gt.xml
./precision_recall.py ./trn_pr.eps -pred ./trn_pred.xml -gt ./trn_gt.xml
./precision_recall.py ./val_pr.eps -pred ./val_pred.xml -gt ./val_gt.xml

./precision_recall.py ./vict_pr.eps -pred ./tst_pred.xml ./trn_pred.xml ./val_pred.xml -gt ./tst_gt.xml ./trn_gt.xml ./val_gt.xml -cls
\end{lstlisting}
