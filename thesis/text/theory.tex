\chapter{Theory}

\section{Related work}

\section{Used neural networks} \label{nets}

The neural networks (sometimes also called artificial neural networks or ANNs) are a powerful tool of today's machine learning. The main component is an {\em artificial neuron}, a computational unit which takes an input and computes a predefined (usually linear) function with its internal parameters. This output is then optionally fed through (usually nonlinear) {\em activation function} to introduce nonlinearities in the output. The artificial neurons can be stacked next to each other to form layers, and if we connect multiple layers together, we have a neural network. We can think of the neural network as a nonlinear transformation function with multiple internal parameters.

The process of training the neural network to give the output we desire then consists of feeding the input data into the network and evaluating the performance by the {\em loss function}, which computes a real-valued number associating the actual output of the network with a notion of a "badness" in comparison with the expected output. This loss function could be for example a norm of a difference between the output of the network and the output given by a human in the case of image labeling or it could be more complex function altogether. The loss function is then minimized with respect to the internal parameters of the neural network by gradient descent algorithm. The most used gradient descent algorithm is a stochastic descent and its variants such as Adam~\cite{adam} or Adagrad~\cite{adagrad}.

If the loss function is well defined over the problem set, then the network will give the desired results at the global minimum of the loss function. However, since this function is a function of the {\em parameters} of the network, it is generally not convex and highly dimensional, and therefore it is hard to reach the global minimum. LeCun~\cite{efbackprop} gave numerous tricks to improve the likelihood of finding a good enough local minimum.

The neural layers we introduced above are usually called {\em fully connected} because all the outputs from one layer are connected to all the neurons from the next layer. This was one of the first formulations of artificial neural networks~\cite{orignet}. However, these fully connected layers are not well suited for computer vision applications, since we would like to have the same response to the particular object in the image regardless of its position or orientation. To overcome this issue, the {\em convolutional} layers~\cite{convnet}, which perform a mathematical operation of convolution over the input, were introduced. Quite often these convolutional layers are followed by the fully connected layers at the end of the network.

\subsection{Generative adversarial network (GAN)}

A generative adversarial network is a concept by Ian Goodfellow~\cite{origgan} aimed at learning to generate a sample from a particular distribution. The main goal is to train a {\em generator} network to produce samples from the target distribution given a sample from some noise distribution. In order to achieve this, a second network called {\em discriminator} is introduced, and its main goal is to distinguish between the samples from the real target distribution and "fake" samples produced by the generator network given a noise sample. If the whole setup is modeled in such a way that the trained discriminator outputs a scalar assigning a probability of the sample coming from the target distribution, the generator is then trying to produce the samples that are convincing enough to the discriminator so that discriminator's output for the generated samples is as close to 1 as possible. This setup was originally formulated within the maximum log-likelihood estimation setup. It could be seen as a two-player minimax game with the value function $V(G, D)$ shown in equation~\ref{gangame}, where $G$ and $D$ are generator and discriminator functions respectively, $p_{target}$ is a target distribution and $p_{noise}$ is a noise distribution that is usually chosen as a uniform, however it could be any other source of noise data.

\begin{equation}
\min_G \max_D V(G, D) = \EX_{\bm{x}\sim p_{target}}[\log D(\bm{x})] + \EX_{\bm{z}\sim p_{noise}} [\log(1 - D(G(\bm{z})))]
\label{gangame}
\end{equation}

This formulation immediately yields loss functions for the generator (equation \ref{ganlossg}) and discriminator (equation \ref{ganlossd}) where $\bm{x}$ are the samples from the target distribution that we present to the networks during the learning and $\bm{z}$ is a noise sampled at each iteration of the training algorithm.

\begin{equation}
\loss_G = \log(1 - D(G(\bm{z})))
\label{ganlossg}
\end{equation}

\begin{equation}
\loss_D = - (\log D(\bm{x}) + \log(1 - D(G(\bm{z}))))
\label{ganlossd}
\end{equation}

It was theoretically shown~\cite{origgan} that in the case of generator and discriminator having enough capacity this setup allows to train the generator to be able to generate samples indistinguishable from the samples from $p_{target}$. However this is not easily achievable in practice. One of the main problems is that generator usually does not have this infinite capacity. More problems stem from the fact that the original loss function (equation \ref{ganlossg}) for the generator does not provide strong enough gradients early on in the process of training, therefore a new loss function with the same theoretical properties, but stronger gradients was introduced as shown in the equation \ref{ganlossgg}.

\begin{equation}
\loss_G = -\log(D(G(\bm{z})))
\label{ganlossgg}
\end{equation}

In practice, we are trying to find the Nash equilibrium~\cite{nash} of a highly dimensional, non-convex function and while we can obtain gradients for this function using training samples, there is no known algorithm to solve this game exactly~\cite{improvedgan}. Therefore we must resort to heuristics such as optimizing discriminator near its optimum for every given sample {\em before} we optimize generator using multiple optimization steps of the discriminator if needed.

Another problem that could very easily occur is a {\em mode collapse} of the generator -- point, where generator does not use its full potential and generates a fixed point for multiple inputs keeping discriminator in the dark. Since the generator receives its gradients from the discriminator and discriminator cannot give any useful information anymore, the generator will not be updated in any sensible direction past the point where the mode collapse occurred.

\subsection{GAN variants}

Since the inception of GANs, many variants emerged trying to overcome some of the issues outlined in the previous subsection. According to DeepHunt~\cite{deephunt}, there were 354 papers proposing a variation of GAN as of 10\textsuperscript{th} May 2018. Most of these improvements revolve around redefining the loss functions and introducing various tricks to achieve better training stability.

In the following subsections will be shortly described some of these variants with their particular improvements and differences of original GAN.

\subsubsection{DCGAN -- Deep Convolutional GAN}
DCGAN~\cite{dcgan} is not a variant of GAN per se, as it mostly involves guidelines for stable training of GAN, when discriminator and generator consist of multiple convolutional layers. The said guidelines can be briefly summarized as:
\begin{itemize}
\item Use strided convolution and deconvolution instead of pooling layers. The reasoning behind this is to allow the networks to find their own representations of up sampling and down sampling.
\item Use batch normalization~\cite{batchnorm} everywhere applicable (i.e. in every layer except last). This allows to get more stable gradients for backpropagation.
\item Do not use fully connected layers that are not the direct output of the discriminator. If there are hidden fully connected layers, then the model stability might improve, however it reduces convergence speed of the training process.
\item Use ReLU~\cite{relu} activation for generator's layers except the last layer using hyperbolic tangent. It was observed, that ReLU helps convergence speed of the training process the most.
\item Use LeakyReLU~\cite{leakyrelu} activation for discriminator's layers. This seems to be especially helpful in higher resolution settings.
\item Use Adam~\cite{adam} optimizer with {\em different} hyperparameters than the usual default. Especially necessary is to lower the learning rate and momentum terms.
\end{itemize}

\subsubsection{LSGAN -- Least Squares GAN}

\subsection{CycleGAN} \label{cyclegan}

\section{Description of LiDAR}
