\chapter{Experiments}

In this chapter we will show evaluation of two different network architectures, VGG16~\cite{vgg16} and ZFNet~\cite{zfnet}. The datasets used for evaluation were our synthesised victims dataset and KITTI~\cite{kitti} object detection dataset. All predictions were marked as matched, if the overlap of predicted region and ground truth region had intersection over union (IoU) at least 50~\% (argument \pyarg{over} of tool \hyperref[pr]{\texttt{precision\_recall.py}} set to 0.5).

Data from our experiments can be found at \url{https://gitlab.fel.cvut.cz/jasekota/jasek-thesis-data}.

\section{Datasets}
Both datasets contain subsets to use for training and validation and Victims dataset also contains usable testing subset.

\subsection{Victims dataset}
Victims dataset is a dataset that artificially merges real data from various sources -- all images were generated by letting random 3D models of humans "fall" into the scene as if they were victims of a crime or a natural disaster. Therefore this dataset proves to be quite challenging since the position and appearance of object to be detected is deformed compared to standard datasets.

The whole dataset contains 4986 images and is split into training, validation and testing subset which all contain approximate third of images -- training subset contains 1604 images, validation subset contains 1645 images and testing subset contains 1737 images. Virtually all of these images contain only one object of class person -- there is 4989 objects in the whole dataset and 4986 images. For obvious reasons, all of them are only positive examples.

This dataset did not have any ground truth files, instead it used only mask above each image to depict the sought object. Therefore it is needed to first create ground truth files by using \hyperref[bbox]{\texttt{victims\_bbox.py}} tool.

Example of images from Victims dataset can be seen at figure \ref{victex}

\begin{figure}[!h]
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=0.98\linewidth,keepaspectratio]{img/vict1.png}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=0.98\linewidth,keepaspectratio]{img/vict2.png}
\end{subfigure}
\caption{Example of images from Victims dataset}
\label{victex}
\end{figure}

\subsection{KITTI dataset}

KITTI~\cite{kitti} dataset is a standard dataset used for evaluating object detection and recognition algorithms in automated driving. The dataset is split into training and testing subset by its authors, however only ground truth files for training subset are accessible by public. The ground truth files for testing subset are private and you can evaluate your algorithm on testing subset by submission of your results on KITTI server. This methodology was not suitable for our evaluation since we re-trained our networks on many different settings, so therefore we ignored testing subset and split training subset into training and validation portions in approximate ratio of 7:3. Training portion contained 5267 images and validation portion contained 2214 images totalling in 7481 images and we re-trained our networks only on training portion.

This dataset contains three different classes -- Car, Pedestrian and Cyclist. Class Car has 20160 instances in training portion and 8582 in validation portion totalling in 28742 instances throughout the whole original training subset. Class Pedestrian has 3298 instances in training portion and 1189 in validation portion totalling in 4487 instances throughout the whole original training subset. Class Cyclist has 1174 instances in training portion and 453 instances in validation portion totalling in 1627 instances throughout the whole original training subset. We can see that class Car has 17.7~times more instances than class Cyclist and about 6.4~times more instances than class Pedestrian. This ratio is more or less consistent within both portions of original training dataset.

Examples of images from KITTI dataset can be seen on figure \ref{kittiex}

\begin{figure}[!h]
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=0.98\linewidth,keepaspectratio]{img/kitti1.png}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=0.98\linewidth,keepaspectratio]{img/kitti2.png}
\end{subfigure}
\caption{Example of images from KITTI dataset}
\label{kittiex}
\end{figure}

\section{Evaluation of original networks} \label{orig}

We show evaluation of networks that were trained only on VOC2007~\cite{voc2007} dataset as obtained from original Faster \rcnn{} paper and therefore the evaluation will be performed on whole datasets.

\subsection{Victims dataset}
This dataset is challenging, since the only correctly classified class was person and in a lot of the images, the person is deformed into victim position which generally does not resemble normal human position in which you would expect a person to be. Because of these deformations, the network is not performing as well as one might expect. Most probable reason for expected decrease in performance is the fact, that dataset actually used for training these networks (VOC2007~\cite{voc2007} training and validation datasets) did not contain many examples of people appearing in these unnatural positions.

On figure \ref{vicper} we can see total performance for all three subsets combined into the whole dataset evaluated by VGG16 network and ZFNet respectively. It is clearly visible, that performance of VGG16 is considerably higher than the performance of ZFNet. This is compensated by shorter runtime for ZFNet, as shown in \ref{time}, but the runtime improvement is not that significant to justify such a drastic decrease in performance.

\begin{figure}[!]
\includegraphics[width=0.7\textwidth,keepaspectratio]{img/both/vict_cmp.eps} 
\caption{Performance on whole victims dataset}
\label{vicper}
\end{figure}

What might be of concern is the fact that none of these architectures were able to achieve perfect recall. This is due to the way Faster \rcnn{} network operates -- it selects only 300 best predictions (and even then some of them have confidence close to 0) and therefore some of the predictions that would amount to higher recall (with obvious loss of precision) are not selected by the network.

\subsection{KITTI dataset}
Figure \ref{kittio} shows precision-recall curves for whole training dataset evaluated by VGG16 and ZFNet networks respectively. Ground truth files were obtained by \hyperref[ktx]{\texttt{kitti\_to\_xml.py}} tool.

\begin{figure}[!]
\includegraphics[width=0.7\textwidth, keepaspectratio]{img/both/kitti_cmp.eps}
\caption{Performance on KITTI dataset measured on all three classes}
\label{kittio}
\end{figure}

Once again you can see much better performance by VGG16 architecture than by ZFNet. Same as on victims dataset, we were not able to achieve perfect recall, even worse, our maximal recall values were even lower. It can be seen that precision starts to drop rapidly in both networks after hitting recall of about 0.3. One can argue that this implies, that KITTI dataset is even harder than victims dataset -- once again though, those values are on networks that were not specifically trained for KITTI dataset. Given this, the results are not as bad as they might seem on the first sight.

Figure \ref{kittic} depicts performance evaluation on whole KITTI training dataset being broken down by each class. It is visible, that class Car was the most succesful one. What is however quite alarming is almost complete absence of correctly classified class Cyclist. One can attribute it to almost no training examples of class \pyarg{bike} in VOC2007 training dataset. The rule of VGG16 net outperforming ZFNEt holds in every class except class Cyclist.

\begin{figure}[!]
\includegraphics[width=0.7\textwidth, keepaspectratio]{img/both/kitti_cls_cmp.eps}
\caption{Performance on KITTI dataset broken down by different classes}
\label{kittic}
\end{figure}

\section{Evaluation of re-trained networks} \label{our}

In this section we will evaluate re-trained networks specifically trained for concrete tasks. Each network was trained 5~times with different amount of training iterations by Caffe framework -- 2000, 4000, 6000, 8000 and 10000 iterations. Evaluation was then performed only on the portion of dataset that was not present in re-training phase. For KITTI dataset it was the validation portion of the training subset consisting of 2214 images, for Victims dataset it was the testing and validation subsets put together consisting of 3382 images overall.

\subsection{VGG16 network re-trained on KITTI dataset}

Figure \ref{vggkittiall} depicts performance of VGG16 network re-trained on KITTI dataset evaluated for all three classes together. It can be seen that re-training of VGG16 network increased performance as expected. Increasing number of iterations of Caffe solver performing re-training kept improving the performance of a network, however with each increase of number of iterations, the increase in performance was lower. Quite interestingly, re-training with 6000 iterations performed better than 8000 iterations. It seems that limit for recall on Faster~\rcnn{} network is close to value of 0.75.

\begin{figure}[!]
\includegraphics[width=0.7\textwidth, keepaspectratio]{img/vgg/vgg_kitti_all.eps}
\caption[Performance of VGG16 network on KITTI dataset]{Performance on KITTI dataset of VGG16 network re-trained on KITTI dataset measured on all three classes}
\label{vggkittiall}
\end{figure}

Figures \ref{vggkittic}, \ref{vggkittip} and \ref{vggkittib} show performances of such re-trained network on classes Car, Pedestrian and Cyclist respectively. Class Car is significantly outperforming both other classes -- this can be possibly attributed to much higher number of instances of class Car in training dataset. But since there are so many more objects of class Car, overall performance as seen on figure \ref{vggkittiall} is just slightly worse than the performance of class Car - it simply outweights the worse performance of other classes.


\begin{figure}[!]
\includegraphics[width=0.7\textwidth, keepaspectratio]{img/vgg/vgg_kitti_car.eps}
\caption[Performance of VGG16 network on KITTI dataset, class Car]{Performance on KITTI dataset of VGG16 network re-trained on KITTI dataset measured on class Car}
\label{vggkittic}
\end{figure}

\begin{figure}[!]
\includegraphics[width=0.7\textwidth, keepaspectratio]{img/vgg/vgg_kitti_person.eps}
\caption[Performance of VGG16 network on KITTI dataset, class Pedestrian]{Performance on KITTI dataset of VGG16 network re-trained on KITTI dataset measured on class Pedestrian}
\label{vggkittip}
\end{figure}

\begin{figure}[!]
\includegraphics[width=0.7\textwidth, keepaspectratio]{img/vgg/vgg_kitti_bike.eps}
\caption[Performance of VGG16 network on KITTI dataset, class Cyclist]{Performance on KITTI dataset of VGG16 network re-trained on KITTI dataset measured on class Cyclist}
\label{vggkittib}
\end{figure}

Another observation is the large improvement of class Cyclist over untrained network. For the network with 10000 iterations, it even outperformed class Pedestrian which has 2.81~times more objects in training dataset.

\subsection{VGG16 network re-trained on Victims dataset}

Figure \ref{vggvictall} shows performance of VGG16 network re-trained on Victims dataset. Performance rapidly increased to precision values being above around 0.95 for recall values of 0.9 for networks re-trained by 8000 and 10000 iterations. However it seems that this might be maximal achievable performance since performance for 8000 and 10000 iterations are nearly identical. Much higher performance on Victims dataset than the performance on KITTI dataset is most likely to be attributed to the fact that Victims dataset is a lot more consistent than KITTI dataset therefore having training subset more closely related to the testing and validation subsets. However, another probable cause of such high performance might be overfitting on our dataset. To investigate further this cause we would need independent dataset that is closely related to Victims dataset but comes from a different domain.

\begin{figure}[!]
\includegraphics[width=0.7\textwidth, keepaspectratio]{img/vgg/vgg_vict_all.eps}
\caption[Performance of VGG16 network on Victims dataset]{Performance on Victims dataset of VGG16 network re-trained on Victims dataset}
\label{vggvictall}
\end{figure}

\subsection{VGG16 network re-trained on KITTI and Victims datasets}

In another experiment we were re-training the networks on both training datasets together. Since such network was re-trained on both datasets, we can evaluate them on both datasets as well.

\subsubsection{Evaluation of KITTI dataset by VGG16 network re-trained on both datasets}

Figure \ref{vggkittivall} depicts performance of VGG16 network re-trained on both datasets evaluated on all three classes of KITTI dataset. We can see that while the increasing tendence in performance is fairly similar to such in network re-trained only on KITTI dataset, amount of the increase is lower, most notably in network re-trained only by 2000 iterations. Figures \ref{vggkittivc}, \ref{vggkittivp} and \ref{vggkittivb} show performance on classes Car, Pedestrian and Cyclist respectively. One would assume that the most decrease in comparison to network re-trained only on KITTI dataset would occur in class Pedestrian since Victims dataset contains only occurences of class Person which are from completely different settings, however the most decrease is in class Cyclist -- we attribute this to even higher underrepresentation of class Cyclist in training set.

\begin{figure}[!]
\includegraphics[width=0.7\textwidth, keepaspectratio]{img/vgg/vgg_kitti_vict_all.eps}
\caption[Performance of VGG16 network on KITTI+Victims datasets]{Performance on KITTI dataset of VGG16 network re-trained on both datasets measured on all three classes}
\label{vggkittivall}
\end{figure}

\begin{figure}[!]
\includegraphics[width=0.7\textwidth, keepaspectratio]{img/vgg/vgg_kitti_vict_car.eps}
\caption[Performance of VGG16 network on KITTI+Victims datasets, class Car]{Performance on KITTI dataset of VGG16 network re-trained on both datasets measured on class Car}
\label{vggkittivc}
\end{figure}

\begin{figure}[!]
\includegraphics[width=0.7\textwidth, keepaspectratio]{img/vgg/vgg_kitti_vict_person.eps}
\caption[Performance of VGG16 network on KITTI+Victims datasets, class Pedestrian]{Performance on KITTI dataset of VGG16 network re-trained on both datasets measured on class Pedestrian}
\label{vggkittivp}
\end{figure}

\begin{figure}[!]
\includegraphics[width=0.7\textwidth, keepaspectratio]{img/vgg/vgg_kitti_vict_bike.eps}
\caption[Performance of VGG16 network on KITTI+Victims datasets, class Cyclist]{Performance on KITTI dataset of VGG16 network re-trained on both datasets measured on class Cyclist}
\label{vggkittivb}
\end{figure}

Figure \ref{vggkittivcmp} shows comparison of performances of network re-trained by 10000 iterations only on KITTI dataset and on both datasets so we can clearly see that although the perfomance is better if network is re-trained for one task only, the decrease in performance is not that harsh and it might be actually suitable to train such network on multiple dataset in order to use only one network for recognition of multiple different datasets afterwards.

\begin{figure}[!]
\includegraphics[width=0.7\textwidth, keepaspectratio]{img/vgg/vgg_kitti_vict_cmp.eps}
\caption[Comparison of performances of VGG16 networks, KITTI dataset]{Comparison of performances on KITTI dataset of VGG16 network re-trained on KITTI dataset and on both datasets}
\label{vggkittivcmp}
\end{figure}

\subsubsection{Evaluation of Victims dataset by VGG16 network re-trained on both datasets}
The situation with Victims dataset is quite similar to the one of KITTI dataset. Figure \ref{vggvkall} shows performance of VGG16 network re-trained on both datasets evaluated on Victims dataset. Once again it is lower than performance of such network re-trained only on Victims dataset however performance is still quite considerably high. Figure \ref{vggvkcmp} shows similar comparison as figure \ref{vggkittivcmp} only for Victims dataset.

\begin{figure}[!]
\includegraphics[width=0.7\textwidth, keepaspectratio]{img/vgg/vgg_vict_kitti_all.eps}
\caption[Performance of VGG16 network on Victims+KITTI datasets]{Performance on Victims dataset of VGG16 network re-trained on both datasets}
\label{vggvkall}
\end{figure}

\begin{figure}[!]
\includegraphics[width=0.7\textwidth, keepaspectratio]{img/vgg/vgg_vict_kitti_cmp.eps}
\caption[Comparison of performances of VGG16 networks, Victims dataset]{Comparison of performances on Victims dataset of VGG16 network re-trained on KITTI dataset and on both datasets}
\label{vggvkcmp}
\end{figure}

\begin{figure}[!]
\includegraphics[width=0.7\textwidth, keepaspectratio]{img/zf/zf_kitti_all.eps}
\caption[Performance of ZFNet network on KITTI dataset]{Performance on KITTI dataset of ZFNet network re-trained on KITTI dataset measured on all three classes}
\label{zfkittiall}
\end{figure}
\clearpage

\subsection{ZFNet network re-trained on KITTI dataset}

ZFNet performed quite badly on re-training overall. It seems that training method (described in \ref{train}) is not suitable for ZFNet since it actually performed worse than the original network trained only on VOC2007~\cite{voc2007} trainval. Another reason for such decrease might be in incorrect learning parameters of a network however the parameters were the same as used in original Faster \rcnn~\cite{faster} paper.

Figure \ref{zfkittiall} shows performance of ZFNet network re-trained on KITTI dataset. As you can see, the performance actually decreased and number of iterations (at least in the range of 2000 - 10000) had virtually no effect on amount of decrease. If you break down the previous figure by measured class, we get figures \ref{zfkittic} for class Car, \ref{zfkittip} for class Pedestrian and \ref{zfkittib} for class Cyclist. What is quite interesting is the fact, that performance for class Cyclist actually increased but only because it was already quite bad at the beginning.


\begin{figure}[!]
\includegraphics[width=0.7\textwidth, keepaspectratio]{img/zf/zf_kitti_car.eps}
\caption[Performance of ZFNet network on KITTI dataset, class Car]{Performance on KITTI dataset of ZFNet network re-trained on KITTI dataset measured on class Car}
\label{zfkittic}
\end{figure}

\begin{figure}[!]
\includegraphics[width=0.7\textwidth, keepaspectratio]{img/zf/zf_kitti_person.eps}
\caption[Performance of ZFNet network on KITTI dataset, class Pedestrian]{Performance on KITTI dataset of ZFNet network re-trained on KITTI dataset measured on class Pedestrian}
\label{zfkittip}
\end{figure}

\begin{figure}[!]
\includegraphics[width=0.7\textwidth, keepaspectratio]{img/zf/zf_kitti_bike.eps}
\caption[Performance of ZFNet network on KITTI dataset, class Cyclist]{Performance on KITTI dataset of ZFNet network re-trained on KITTI dataset measured on class Cyclist}
\label{zfkittib}
\end{figure}

\begin{figure}[!]
\includegraphics[width=0.7\textwidth, keepaspectratio]{img/zf/zf_vict_all.eps}
\caption[Performance of ZFNet network on Victims dataset]{Performance on Victims dataset of ZFNet network re-trained on Victims dataset}
\label{zfvictall}
\end{figure}

\subsection{ZFNet network re-trained on Victims dataset}
Figure \ref{zfvictall} shows performance of ZFNet network re-trained on Victims dataset. Surprisingly, although it preformed quite badly on KITTI dataset, the network actually improved on Victims dataset, though not by much. The performance still remains below the performance of untrained VGG16 network. Quite interesting is the fact, that the ZFNet network re-trained by 4000 iterations performed worse than the original ZFNet network while all the iterations outperform it.

\subsection{ZFNet network re-trained on KITTI and Victims datasets}
\subsubsection{Evaluation of KITTI dataset by ZFNet network re-trained on both datasets}
Figure \ref{zfkittivall} depicts performance of ZFNet network re-trained on both datasets evaluated on all three classes of KITTI dataset. Once again we can see that ZFNet network is not suitable for re-training with our parameters and the results are as bad as the results of the network re-trained only on KITTI dataset. Figures \ref{zfkittivc}, \ref{zfkittivp} and \ref{zfkittivb} show performance on classes Car, Pedestrian and Cyclist respectively. The performance is about the same as for the network fine.tuned only on KITTI dataset. Figure \ref{zfkittivcmp} shows comparison of the performance of the network re-trained by 10000 iterations only on KITTI dataset and on both datasets. We can see that network re-trained only on KITTI dataset was slightly worse, but the difference between those two is marginal.

\begin{figure}[!]
\includegraphics[width=0.7\textwidth, keepaspectratio]{img/zf/zf_kitti_vict_all.eps}
\caption[Performance of ZFNet network on KITTI+Victims dataset]{Performance on KITTI dataset of ZFNet network re-trained on both datasets measured on all three classes}
\label{zfkittivall}
\end{figure}

\begin{figure}[!]
\includegraphics[width=0.7\textwidth, keepaspectratio]{img/zf/zf_kitti_vict_car.eps}
\caption[Performance of ZFNet network on KITTI+Victims dataset, class Car]{Performance on KITTI dataset of ZFNet network re-trained on both datasets measured on class Car}
\label{zfkittivc}
\end{figure}

\begin{figure}[!]
\includegraphics[width=0.7\textwidth, keepaspectratio]{img/zf/zf_kitti_vict_person.eps}
\caption[Performance of ZFNet network on KITTI+Victims dataset, class Pedestrian]{Performance on KITTI dataset of ZFNet network re-trained on both datasets measured on class Pedestrian}
\label{zfkittivp}
\end{figure}

\begin{figure}[!]
\includegraphics[width=0.7\textwidth, keepaspectratio]{img/zf/zf_kitti_vict_bike.eps}
\caption[Performance of ZFNet network on KITTI+Victims dataset, class Cyclist]{Performance on KITTI dataset of ZFNet network re-trained on both datasets measured on class Cyclist}
\label{zfkittivb}
\end{figure}
\clearpage
\begin{figure}[!]
\includegraphics[width=0.7\textwidth, keepaspectratio]{img/zf/zf_kitti_vict_cmp.eps}
\caption[Comparison of performances of ZFNet networks, KITTI dataset]{Comparison of performances on KITTI dataset of ZFNet network re-trained on KITTI dataset and on both datasets}
\label{zfkittivcmp}
\end{figure}
\subsubsection{Evaluation of Victims dataset by ZFNet network re-trained on both datasets}

\begin{figure}[!]
\includegraphics[width=0.7\textwidth, keepaspectratio]{img/zf/zf_vict_kitti_all.eps}
\caption[Performance of ZFNet network on Victims+KITTI dataset]{Performance on Victims dataset of ZFNet network re-trained on both datasets}
\label{zfvkall}
\end{figure}

\begin{figure}[!]
\includegraphics[width=0.7\textwidth, keepaspectratio]{img/zf/zf_vict_kitti_cmp.eps}
\caption[Comparison of performances of ZFNet networks, Victims dataset]{Comparison of performances on Victims dataset of ZFNet network re-trained on KITTI dataset and on both datasets}
\label{zfvkcmp}
\end{figure}

The tendence that Victims dataset is easier for re-training holds even for network re-trained on both datasets. However it is still not able to achieve performance of original VGG16 network, not to mention performance of VGG16 network re-trained specifically for Victims dataset. Figure \ref{zfvkall} shows performance of such network. Figure \ref{zfvkcmp} compares performances of ZFNet networks re-trained on Victims dataset only and on Victims and KITTI dataset. We can see, that training specifically for particular dataset only, yields better resuls even for ZFNet network.

\clearpage
\section{Time evaluation} \label{time}

Due to hardware limitations on the server where we were running the experiments and unexpected change of hardware during experiments (upgrade from NVidia GeForce GTX Titan Black to NVidia Tesla K40c) we were unable to ensure same conditions for all experiments required for fair comparison of timing. However since one experiment consisted of re-training a network and running tool \hyperref[rec]{\pyarg{recognize.py}} on all datasets we have (including configurations such as re-training on KITTI dataset and recognizing of Victims dataset which makes no sense to later evaluate performance on, but is easier to automate), and since each GPU had the same amount of such experiments, it is actually feasible to compare timing for recognition portion. We do not have any timing data for re-training portion of the experiments, however by experience, re-training ZFNet network was about 3 times faster than re-training VGG16 network.

Table \ref{timebd} shows average times for both datasets expressed in miliseconds needed to process one image. The times could be most likely a bit faster since more comupting jobs were running at GPUs concurrently, however the ratio in between those two architecture would still most likely stay the same, showing that recognizing an image by ZFNet is about 2.4 times faster than by VGG16 network.

Table \ref{timedd} shows average times dependant on dataset being currently recognized. We can see that KITTI dataset was slightly faster than Victims dataset, however the difference is a lot more significant for VGG16 network than for ZFNet.

Tables \ref{timec1} and \ref{timec2} shows runtime performance of original networks measured on CPU (Intel\circledR{ }Xeon\circledR~{ }E5-2630 v3). VGG16 architecture proved again to be about 2 times slower than ZFNet. Runtime performance on 8-core CPU is about 11.7 times slower than running on GPUs. KITTI dataset recognition was again faster than recognition of Victims dataset, on CPU a lot more notably than on GPU.

\begin{table}[!h]
\begin{tabular}{r|ccc}
 & Average time [ms] & Min time [ms] & Max time [ms] \\
\hline
All experiments & 252.61 & 60.17 & 1459.43 \\
\textbf{VGG16} architecture & 350.14 & 149.78 & 1459.43 \\
\textbf{ZFNet} architecture & 141.09 & 60.17 & 1382.91
\end{tabular}
\caption{Time comparison of different architectures for both datasets measured on GPU}
\label{timebd}
\end{table}

\begin{table}[!h]
\begin{tabular}{r|ccc}
 & Average time [ms] & Min time [ms] & Max time [ms] \\
\hline
\multicolumn{4}{c}{KITTI dataset} \\ \hline
Both architectures & 228.50 & 68.62 & 1035.76 \\
\textbf{VGG16} architecture & 316.86 & 149.78 & 1035.76 \\
\textbf{ZFNet} architecture & 140.14 & 68.62 & 493.94 \\
\hline
\multicolumn{4}{c}{Victims dataset} \\ \hline
Both architectures & 271.29 & 60.17 & 1459.43 \\
\textbf{VGG16} architecture & 400.07 & 189.22 & 1459.43 \\
\textbf{ZFNet} architecture & 142.51 & 60.17 & 1382.91 \\
\end{tabular}
\caption{Time comparison of different architectures and different datasets measured on GPU}
\label{timedd}
\end{table}

\begin{table}[!h]
\begin{tabular}{r|ccc}
 & Average time [ms] & Min time [ms] & Max time [ms] \\
\hline
All experiments & 2971.88 & 1454.86 & 7958.40 \\
\textbf{VGG16} architecture & 3944.13 & 2775.03 & 7958.40 \\
\textbf{ZFNet} architecture & 1999.63 & 1454.86 & 5359.79
\end{tabular}
\caption{Time comparison of different architectures for both datasets measured on CPU}
\label{timec1}
\end{table}

\begin{table}[!h]
\begin{tabular}{r|ccc}
 & Average time [ms] & Min time [ms] & Max time [ms] \\
\hline
\multicolumn{4}{c}{KITTI dataset} \\ \hline
Both architectures & 2627.41 & 1454.86 & 7958.40 \\
\textbf{VGG16} architecture & 3525.56 & 2775.03 & 7958.40 \\
\textbf{ZFNet} architecture & 1729.26 & 1454.86 & 2740.61 \\
\hline
\multicolumn{4}{c}{Victims dataset} \\ \hline
Both architectures & 3488.72 & 1804.07 & 6373.09 \\
\textbf{VGG16} architecture & 4572.15 & 3702.96 & 6373.09 \\
\textbf{ZFNet} architecture & 2405.30 & 1804.07 & 5359.79 \\
\end{tabular}
\caption{Time comparison of different architectures and different datasets measured on CPU}
\label{timec2}
\end{table}
