\chapter{Programs} \label{programs}

The main program developed for the purpose of this thesis was a Python package \texttt{cycle} implementing modular CycleGAN~\cite{cyclegan} in TensorFlow~\cite{tensorflow} and two programs built on top of this package. This package and associated programs reside in a directory \texttt{mod-cycle-gan} at \url{https://gitlab.fel.cvut.cz/jasekota/master-thesis/tree/master/code/mod-cycle-gan} and will be therefore together referenced as \texttt{mod-cycle-gan}. There is also an utility program written in C++ called \texttt{dat-unpacker} which reads ADTF DAT files used by Valeo company and extracts data from them into an intermediate format similar to the one gathered from GTA. Last portion of the code developed for this thesis is a folder with various Python modules (with critical part of the code written in Cython) and scripts with simple name \texttt{data-processing}. These three programs/packages will be described more in depth in the following sections.

All of the developed code is in the directory \texttt{code} on attached CD and also available at \url{https://gitlab.fel.cvut.cz/jasekota/master-thesis/tree/master/code}.

\section[\texttt{mod-cycle-gan}]{\texttt{mod-cycle-gan} -- Python package \texttt{cycle} and programs \texttt{train.py} and \texttt{test.py}}

Python package \texttt{cycle} is the implementation of CycleGAN~\cite{cyclegan} with large inspiration from GitHub repository of Van Huy at \url{https://github.com/vanhuyz/CycleGAN-TensorFlow}.

\subsection{Exported classes}


\begin{itemize}
\item \texttt{CycleGAN} -- Main class implementing CycleGAN.
\begin{description}
\descitem{\texttt{\_\_init\_\_()}} Constructor of this class takes numerous arguments. First two arguments (\texttt{XtoY, YtoX}) correspond to GANs to be set in cycle fashion (instances of \texttt{nets.GAN} or its subclasses), another two (\texttt{X\_feed, Y\_feed}) are for TFRecords file readers (\texttt{utils.TFReader}) and another two (\texttt{X\_name, Y\_name}) correspond to names of the dataset for pretty printing of logs and Tensorboard messages. Following argument (\texttt{cycle\_lambda}) is a $\lambda$ for cyclic loss function (for more detail see section \ref{cyclegan}). Next argument (\texttt{tb\_verbose}) is a boolean for deciding whether to create summaries for Tensorboard and following argument (\texttt {visualizer}) is a function to use for visualizing the data in Tensorboard -- if this argument is set to \texttt{False} or \texttt{None} then no function will be used for visualization.

Next four arguments (\texttt{learning\_rate, beta1, steps, decay\_from}) control optimization process -- namely initial learning rate for Adam optimizer~\cite{adam}, parameter beta1 of said optimizer, number of steps (where one step corresponds to one batch) and number of steps after which the learning rate starts to decay to eventually stop at zero. Following argument (\texttt{history}) indicates, whether to use history pool according to~\cite{historypool} and finally, last argument (\texttt{graph}) specifies the computational TensorFlow graph in which the model should be created. If it is left as \texttt{None}, then new graph will be created.
\descitem{\texttt{get\_model()}} This method actually creates the full model in TensorFlow graph. As such, it should be only called once. It sets up all the losses and their respective optimizers. This method has no arguments.
\descitem{\texttt{train()}} This method is the main training loop. The only required argument (\texttt{checkpoints\_dir}) is the top-level checkpoints directory in which a new directory for this session is either created if needed or selected as a loading point in case of retrying training. Next two arguments (\texttt{gen\_train, dis\_train}) specify how often should be generator and discriminator trained within one training step. Next argument (\texttt{pool\_size}) specifies the size of the history pool. Following argument (\texttt{load\_model}) specifies a directory from which to load a saved model if retrying. Note that it is a path relative to top-level checkpoints directory. If this argument is \texttt{None}, new directory with current timestamp is created and new training starts. Next argument (\texttt{log\_verbose}) is a boolean specifying whether to log current loss periodically or not. Next argument (\texttt{param\_string}) specifies string which is a serialized version of arguments with which \hyperref[trainpy]{\texttt{train.py}} script was executed. This string will be saved to checkpoint directory with name \texttt{params.flagfile}. Last argument (\texttt{export\_final}) specifies whether to export final model after training as a binary protobuf used for testing.
\descitem{\texttt{export()}} This method requires two arguments -- first argument (\texttt{sess}) is a session in which a model was run and the second (\texttt{export\_dir}) is a directory in which to save the model. There will be two saved models of names \texttt{\{Xname\}2\{Yname\}.pb} and \texttt{\{Yname\}2\{Xname\}.pb} which can then be used for testing. This method is automatically at the end of the \texttt{train()} method if the last argument (\texttt{export\_final}) was set to \texttt{True}.
\descitem{\texttt{export\_from\_checkpoint()} -- static method} This method is a static counterpart of the \texttt{export()} method. It requires more arguments than method \texttt{export()} because it does not have all the book-keeping information the instance method has. First two arguments (\texttt{XtoY, YtoX}) are instances of GANs with the same model as used for training, another four arguments (\texttt{X\_normer, X\_denormer, Y\_normer, Y\_denormer}) are normalization and denormalization functions to be used for both datasets prior feeding the examples to network and converting them back to useful values. Next argument (\texttt{checkpoint\_dir}) corresponds to checkpoint directory where the model is stored and following argument (\texttt{export\_dir}) specifies directory in which the output models will be saved. Last two arguments (\texttt{X\_name, Y\_name}) correspond to the names of the datasets for easier identification of created models.
\descitem{\texttt{test\_one\_part()} -- static method} This method tests the stored exported model with a NumPy file and saves the important outputs of the network to a new NumPy file. First argument (\texttt{pb\_model}) is a path to an exported binary protobuf model of the network to test. Another argument (\texttt{infile}) specifies the path to the input file to test and next argument (\texttt{outfile}) corresponds to a path of output file. This output file will be a Npz NumPy file with three fields -- \texttt{output} (output generated by corresponding generator), \texttt{d\_input} (value of corresponding discriminator evaluated on input data) and \texttt{d\_output} (value of corresponding discriminator evaluated on output data).

Last argument (\texttt{include\_input}) is a boolean specifying whether to include input data in the output file or not. If set to \texttt{True}, \texttt{outfile} will become larger, however it will be more self-contained.
\end{description}
\item \texttt{utils.TFReader} -- Class for reading TFRecords file, which is a TensorFlow binary format for efficient storage of data and features based on Protobuf.
\begin{description}
\descitem{\texttt{\_\_init\_\_()}} First argument (\texttt{tfrecords\_file}) specifies the path to the TFRecords file to read. Another argument (\texttt{name}) specifies the name of the dataset. This name is rather important, because it needs to be the same as set in TFRecords file \texttt{utils.TFWriter} for parsing of the TFRecords file to be successful. Next argument (\texttt{shape}) is a shape of one example stored in TFRecords file. Since all the data in TFRecords file are stored as flattened arrays, this needs to be set to correct size in order to reshape it to desired size. Next argument (\texttt{shuffle\_buffer\_size}) is passed to the method \texttt{shuffle()} of \texttt{tf.data.Dataset} and as such represents the number of samples used for shuffling. Following two arguments (\texttt{normer, denormer}) are functions operating on tensors for normalizing and denormalizing elements of the dataset (i.e. casting to correct type, squeezing or expanding range, etc.) By default these are identity functions. These functions should be able to accept a keyword \texttt{name} (they are used for exporting). Next argument (\texttt{batch\_size}) is a size of one batch produced by this reader and the last argument (\texttt{num\_threads}) specifies how many threads should be used in operations concerning creating the dataset where applicable.
\descitem{\texttt{feed()}} This method returns new batch of elements from the dataset when run in TensorFlow session. It is used by \texttt{CycleGAN} methods \texttt{get\_model()} and \texttt{train()}. It does not accept any parameters.
\end{description}
\item \texttt{utils.TFWriter} -- Class for creating TFRecords file from NumPy files.
\begin{description}
\descitem{\texttt{\_\_init\_\_()}} The constructor accepts three arguments -- first argument (\texttt{name}) is a name of a dataset. Next argument (\texttt{infiles}) is either a single NumPy file or a list of such files comprising the full dataset. It is expected, that all dimensions except the first one will match within the files. The first dimension represents number of {\em single} elements (with possibly more complex shape, such as $64\times2084\times3$ as is the case in LiDAR-like data used in our experiments) of datasets. Last argument (\texttt{process\_data}) is a function operating on these single elements and tweaking them somehow if needed before storing the data to TFRecords file. The reason, why this argument might be useful (instead of using argument \texttt{normer} of class \texttt{utils.TFReader}) is that this function does not operate on tensors which makes most functions more limiting.
\descitem{\texttt{run()}} This method takes one argument (\texttt{outfile}) specifying path to the output TFRecords file. It will report progress to the default logger (with level \texttt{INFO}) every 10 examples processed.
\end{description}
\item \texttt{utils.DataBuffer} -- Class implementing history pool according to~\cite{historypool}. This class is used by method \texttt{train()} of class \texttt{CycleGAN} and should not be instantiated on its own.
\begin{description}
\descitem{\texttt{\_\_init\_\_()}} Constructor of this class takes three arguments. First argument (\texttt{pool\_size}) manages the size of the pool to be used. It has to be either $-1$ (where essentially there is no pool and this particular instance of the class has no effect) or at least as large as the second argument, \texttt{batch\_size}. Third argument (\texttt{old\_prob}) controls the probability with which the older image is returned by method \texttt{query()} instead of the one that was given. This probability comes to play only when the buffer is filled to its maximum (\texttt{pool\_size}).
\descitem{\texttt{query()}} This method will return the data of the same shape it was fed (by first argument -- \texttt{data}). If the internal buffer was already filled, then it will replace randomly elements of the data forming a batch with a probability given in the constructor by argument \texttt{old\_prob} and swaps the elements it replaced into its buffer in the places of the elements that are used in replacement. If the buffer is not filled yet, it will only store the elements from \texttt{data} argument and not replace them.

Second argument (\texttt{cur\_step}) indicates the global step of the training process in order to be able to return the same data for the same step (for example, if training uses multiple training step for discriminator or generator).
\end{description}
\item \texttt{nets.BaseNet} -- Base class for mapping networks (Generator and Discriminator). This class encapsulates mapping network and if you want to create your own mapping network and feel limited by the capabilities of this, you should subclass it and re-implement method \texttt{transform()}.
\begin{description}
\descitem{\texttt{\_\_init\_\_()}} Constructor of this class takes five arguments. First argument (\texttt{name}) is a name of the network as it will appear in TensorFlow computational graph and this name will encapsulate all of the operations of the network. Second argument (\texttt{network\_desc}) is a string describing layers of the network and will be dissected in more detail at subsection \ref{networkdesc}. Third argument (\texttt{is\_training}) is a boolean indicating whether the network is in a training or testing mode. This is mostly important for norms.

Next argument (\texttt{weight\_lambda}) is a $\lambda$ of weight term of the loss function for this particular network. This was motivated by having lot of networks with skip connection where we wanted to make only small changes to the image and thus minimizing the weights of generators and therefore generating only small perturbations.

Last argument (\texttt{norm}) is a type of normalization used in network layers. Can be either \texttt{'instance'}~\cite{instancenorm}, \texttt{'batch'}~\cite{batchnorm} or anything else for no normalization between layers. It does not make any sense to use different normalizations within one network so this setting can be made global for the whole network.
\descitem{\texttt{\_\_call\_\_()}} This is the way how the mapping induced by this object will be called. It essentially just wraps the call to \texttt{transform()} method inside a variable scope of the name specified by the first argument of the constructor (\texttt{name}) and collects all the trainable variables into the list called \texttt{variables}. This book-keeping is done to ease the subclassing since now the only method to be replaced is \texttt{transform()} without the need to worry about collecting all the trainable variables and placing it under same particular variable scope.
\descitem{\texttt{transform()}} This method accepts one argument (\texttt{data}) -- tensor that will be transformed by the network. It is the core of the class \texttt{nets.BaseNet} and if you decide to write your own mapping network by subclassing, this method {\em must} be implemented. By default, it creates the mapping network according to the argument \texttt{network\_desc} supplied to the constructor. The syntax of this simple string will be more in depth explained at subsection \ref{networkdesc}.
\descitem{\texttt{weight\_loss()}} This method return weight loss of the mapping network defined by equation \ref{wloss}, where $\theta_F$ is a set of trainable variables of a mapping function $F$ represented by this object, $\lambda_{\text{w}F}$ is a multiplier denoting the contribution of this loss term to the overall loss function and $\loss_{\text{w}F}$ is a loss term returned by this method.

\begin{equation}
\loss_{\text{w}F} = \lambda_{\text{w}F} \frac{1}{|\theta_F|} \sum_{\bm{w} \in \theta_F} \norm{\bm{w}}_2^2
\label{wloss}
\end{equation}

\end{description}

\item \texttt{nets.GAN} -- Implementation of Generative Adversarial Network (GAN)~\cite{origgan}. Uses original loss functions.

\begin{description}
\descitem{\texttt{\_\_init\_\_()}} First two arguments (\texttt{gen, dis}) of the constructor are the mapping networks -- generator and discriminator (in the original paper $G(\cdot)$ and $D(\cdot)$), where discriminator should produce real number in a range [0; 1] due to the way how is loss function defined. If the discriminator function's output is of higher dimension than one, then the appropriate loss function is computed in each dimension independently and the final loss is arithmetical mean of these loss functions. If discriminator network is a convolutional network, one can think of this as the loss computed at different patches extracted by the network.

Next two arguments (\texttt{in\_shape, out\_shape}) specify input and output shapes of generator {\em without} the batch size. Though this information could be easily obtained from the generator function, it is there mostly to check that the shapes are correct and indeed what you intended them to be. Next two arguments (\texttt{gen\_lambda, dis\_lambda}) are $\lambda$s that correspond to the weight of the respective terms in the final loss function.
\descitem{\texttt{gen\_loss()}} This method expects one argument -- data of \texttt{in\_shape} that will be fed to generator to produce the loss term of the generator according to the equation \ref{gangenloss}, where $\lambda_G$ is a multiplier denoting the contribution of this loss term, $G(\cdot)$ is a generator mapping, $D(\cdot)$ is a discriminator mapping, $\bm{x}$ is input data for generator mapping and $\loss_{G}$ is a loss term returned by this method.

\begin{equation}
\loss_{G} = -\lambda_G\log(D(G(\bm{x})))
\label{gangenloss}
\end{equation}

Note, that the original formulation of the generator loss function by \cite{origgan} is slightly different (as seen in the equation \ref{origgangenloss} where all the symbols have the same meaning as in the equation \ref{gangenloss}), however it was suggested in the same paper, that the formulation \ref{gangenloss} is equivalent with an important advantage of stronger gradients early in the training process.

\begin{equation}
\loss_{G} = \lambda_G\log(1 - D(G(\bm{x})))
\label{origgangenloss}
\end{equation}

\descitem{\texttt{dis\_loss()}} This method takes two arguments (\texttt{real, fake}) which are both of the \texttt{out\_shape} -- \texttt{real} is a real sample from the target distribution and \texttt{fake} is a result of applying $G(\cdot)$ to a sample from the input distribution. This method then computes the discriminator term of the loss function specified by the equation \ref{gandisloss}, where $\lambda_D$ is a multiplier denoting the contribution of this loss term, $D(\cdot)$ is a discriminator mapping, $\bm{\hat{x}}$ corresponds to \texttt{real} argument, $\bm{y}$ corresponds to \texttt{fake} argument and $\loss_D$ is a loss term returned by this method. Original paper was maximizing the same function without minus sign, and since we are minimizing all terms of the loss functions, we added minus in front of the loss function. The division by 2 is there only to scale both terms equally with respect to the generator loss.

\begin{equation}
\loss_D = -\frac{\lambda_D}{2} (\log(D(\bm{\hat{x}})) + \log(1 - D(\bm{y})))
\label{gandisloss}
\end{equation}

\end{description}

\item \texttt{nets.LSGAN} -- Implementation of Least Squares GAN~\cite{lsgan}. This is a subclass of \texttt{nets.GAN} and as such all of the methods accept the same arguments. The only difference is in the equations governing the computation of respective terms of the loss function in methods \texttt{gen\_loss()} and \texttt{dis\_loss()}.
\begin{description}
\descitem{\texttt{gen\_loss()}} This method implements the generator loss function according to the equation \ref{lsgangenloss}. The meaning of the used symbols is the same as in equation \ref{gangenloss}. The reason for number 0.9 comes from the label smoothing proposed by~\cite{improvedgan,smooth}.
\begin{equation}
\loss_G = \lambda_G \norm{D(G(\bm{x})) - 0.9}_2^2
\label{lsgangenloss}
\end{equation}
\descitem{\texttt{dis\_loss()}} This  method implements the discriminator loss function according to the equation \ref{lsgandisloss}. The meaning of the used symbols is the same as in equation \ref{gandisloss}.
\begin{equation}
\loss_D = \frac{\lambda_D}{2} (\norm{D(\bm{\hat{x}}) - 0.9}_2^2 + \norm{D(\bm{y})}^2)
\label{lsgandisloss}
\end{equation}

\end{description}
\item \texttt{nets.WGAN} -- Implementation of Wasserstein GAN with gradient penalty \cite{wgan}. This is a subclass of \texttt{nets.GAN} as well, however it introduces one more term to the loss function, so called gradient penalty. This is implemented in method \texttt{grad\_loss()}.
\begin{description}
\descitem{\texttt{\_\_init\_\_()}} The constructor takes the same arguments as the constructor of \texttt{nets.GAN} with one more argument (\texttt{grad\_lambda}) specifying the weight of the gradient penalty.
\descitem{\texttt{gen\_loss()}} This method implements the generator loss function according to the equation \ref{wgangenloss}. The meaning of the symbols is the same as in equation \ref{gangenloss}.
\begin{equation}
\loss_G = -\lambda_GD(G(\bm{x}))
\label{wgangenloss}
\end{equation}
\descitem{\texttt{dis\_loss()}} This method implements the discriminator loss function according to the equation \ref{wgandisloss}. The meaning of the used symbols is the same as in equation \ref{gandisloss}. Note that the gradient penalty term of the loss function is computed in the method \texttt{grad\_loss()}
\begin{equation}
\loss_D = \frac{\lambda_D}{2}(D(\bm{y}) - D(\bm{\hat{x}}))
\label{wgandisloss}
\end{equation}

\descitem{\texttt{grad\_loss()}} This method computes the gradient penalty term according to the equation \ref{wgangradloss}, where $\lambda_{DGP}$ is a multiplier denoting the contribution of the gradient penalty term to the overall loss, $\bm{\tilde{x}} = \epsilon\bm{\hat{x}} + (1-\epsilon)\bm{y}$, $\epsilon$ is a random number from [0,1] and $\loss_{DGP}$ is a loss term returned by this method.

\begin{equation}
\loss_{DGP} = \lambda_{DGP}(\norm{\nabla_{\bm{\tilde{x}}}D(\bm{\tilde{x}})}_2 - 1)^2
\label{wgangradloss}
\end{equation}

\descitem{\texttt{full\_dis\_loss()}} This method computes the full loss of the discriminator, $\loss_{DGP} + \loss_D$.
\end{description}
\end{itemize}

\subsection[Parameterization of the mapping networks]{Parameterization of the mapping networks by \texttt{network\_desc}} \label{networkdesc}
The mapping network could be easily parameterized by a special \texttt{network\_desc} string. This string comprises of layers separated by semicolon (\texttt{';'}). All layers comprise of letter from \{\texttt{'c', 'b', 'r', 'f'}\} specifying the layer type, followed by hyphen (\texttt{'-'}) and a list of numerical parameters specific to particular layer each of them separated by hyphen as well. The last part of a layer is again a letter from \{\texttt{'r', 't', 'l', 's', 'i'}\} specifying the used activation function for this particular layer. All of the trainable variables are initialized using Xavier initializer~\cite{xavier} in order to keep the scale of the gradients approximately the same across all layers. Normalization (either instance or batch) is always used before applying activation function.

Note that the parameterization using this notation is rather simple and does not allow all possible configurations of specified layers. If you desire finer control over created layers, then using this \texttt{network\_desc} string is not ideal for you.

The tail of the \texttt{network\_desc} string after last semicolon specifies output operation and could be any number of the letters from the set \{\texttt{'s', 'c', 'a'}\}. These output operations are chained in the order in which they appear in the tail of the \texttt{network\_desc} string.

\subsubsection{Layers description}

\begin{description}
\descitem{\texttt{'c'} -- 2D Convolutional layer~\cite{convnet}} This layer accepts {\em three} integer arguments -- first argument is a kernel size (the kernel will have square shape), second argument is a stride (same in all directions) used in the convolution and third argument specifies the number of filters used (number of channels in the output). For example the string \texttt{'c-7-1-64-r'} specifies the convolutional layer with kernel of size 7, stride 1, 64 output channels and ReLU~\cite{relu} used as activation function.
\descitem{\texttt{'b'} -- 2D Convolutional ResNet~\cite{resnet} block} This layer creates a ResNet block and accepts {\em two} integer arguments. First argument is a kernel size of each layer comprising this block and second argument specifies the number of repetitions of this convolutional layer. Since ResNet block requires the input and output simension to match, stride is implicitly set to 1 and number of the output channels is the same as the number of the input channels. For example, the string \texttt{'b-3-2-r'} specifies the most classical ResNet block comprising of two convolutional layers with kernel size 3, stride 1 and ReLU activation in between of those two layers.
\descitem{\texttt{'r'} -- Resize and 2D Convolutional layer~\cite{resizeconv}} This layer was originally deconvolutional~\cite{deconv} layer, however to mitigate checkerboard artifacts stemming from using deconvolutional layer~\cite{resizeconv}, we decided to use instead resize and convolutional layer. It accepts {\em three} integer arguments and one float argument. First three arguments correspond to the same arguments as regular convolutional layer and last argument corresponds to coefficient of resizing. The resizing is done using method \texttt{tf.image.resize\_images} with resize method \texttt{tf.image.ResizeMethod.NEAREST\_NEIGHBOR}. The number of channels after resizing stays the same as number of channels in the input image. For example, the string \texttt{'r-3-1-32-2-r'} will first resize the input image making it twice as large as input and then perform convolutional operation with kernel of size 3, stride 1, 32 output channels and ReLU as activation function.
\descitem{\texttt{'f'} -- Fully connected layer} This is the simple fully connected layer. It accepts one integer argument specifying the number of output neurons. The input gets flattened before performing it is fed into the neurons.
\end{description}

\subsubsection{Available activation functions}

\begin{itemize}
\item \texttt{'r'} -- Rectified Linear Unit (ReLU)~\cite{relu}
\item \texttt{'l'} -- Leaky Rectified Linear Unit (Leaky ReLU)~\cite{leakyrelu}
\item \texttt{'t'} -- Hyperbolic tangent function defined by $\tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}$
\item \texttt{'s'} -- Sigmoid function defined by $S(x) = \frac{e^x}{e^x + 1}$
\item \texttt{'i'} -- Identity, no nonlinear activation function is used.
\end{itemize}

\subsubsection{Output operation}

These operations are chained in order in which they appear in the tail of the \texttt{network\_desc}. Note, that this part of the \texttt{network\_desc} can be empty if you don't want to use any special output operation.
\begin{itemize}
\item \texttt{'s'} -- Sums the current output with input to the whole mapping network.
\item \texttt{'c'} -- Clip the output of the whole network to the range [-1; 1].
\item \texttt{'a'} -- Use activation function on the output. Since the operating range for most of the networks is [-1; 1], the only activation function that {\em makes sense} to use is $\tanh$, so this function will be used.
\end{itemize}

\subsubsection{Example of the full network}

The full network could be for example parameterized by string\\\texttt{'c-7-1-64-r;c-5-2-128-r;b-3-3-r;r-5-1-64-2-r;c-7-1-3-t;sc'}. This network consists of two regular convolutional layers with kernel sizes 7 and 5, strides 1 and 2 and having 64 and 128 output channels. Both of these layers use ReLU as activation function. Convolutional layers are then followed by one ResNet block with three convolutional layers and kernel size 3 and again, ReLU is used. Next resize operation follows which creates the image double the size and is followed by another two convolutional layers with kernel sizes 5 and 7, both strides equal to 1 and having 64 and 3 output channels. First of these convolutional layers is followed by ReLU activation function, the second one uses $\tanh$ as activation. Output of the last convolutional layer is then added to the original input and this sum is then clipped to the range [-1; 1].

\subsection{Models}

The module \texttt{cycle} contains a folder called \texttt{models} in which the settings for different experiments and mapping networks reside. Each submodule in this folder should correspond to one different parameterization specific to different dataset. Each submodule should export these variables and classes in order to be able to use it as a valid model for CycleGAN:

\begin{description}
\descitem{\texttt{X\_name, Y\_name}} Names of the X and Y dataset.
\descitem{\texttt{X\_DATA\_SHAPE, Y\_DATA\_SHAPE}} Tuples specifying shape of one element of X and Y dataset.
\descitem{\texttt{XY\_Generator, YX\_Generator}} Classes specifying generators from X to Y and from Y to X dataset respectively. Note that these classes should be either \texttt{nets.BaseNet} or its subclasses accepting the same arguments in its constructor.
\descitem{\texttt{X\_Discriminator, Y\_Discriminator}} Classes specifying discriminators of X and Y datasets. Note that these classes should be either \texttt{nets.BaseNet} or its subclasses accepting the same arguments in its constructor.
\descitem{\texttt{X\_normer, Y\_normer}} Functions operating on tensors and accepting keyword argument \texttt{name}. These functions will be used to normalize data from X and Y datasets before feeding them into the network.
\descitem{\texttt{X\_denormer, Y\_denormer}} Functions operating on tensors and accepting keyword argument \texttt{name}. These functions will be used to denormalize outputs from the network. They should be inverse functions to functions \texttt{X\_normer} and \texttt{Y\_normer}.
\descitem{\texttt{visualize} -- optional} Function to visualize data during training. This function should accept three batches of images, original data, output of first generator and output of second generator applied to the output of the first generator. The function should return {\em one} batch of images (with same batch size as it received) to show at appropriate place in TensorBoard, therefore using concatenate operation is preferred. This function is necessary to implement if you specify visualizing in \hyperref[trainpy]{\texttt{train.py}} script.
\end{description}

For reference implementation of a particular model for LiDAR-like datasets, see folder \texttt{mod-cycle-gan/cycle/models/lidar}.

\subsection{Scripts \texttt{train.py} and \texttt{test.py}} \label{trainpy}

The folder \texttt{mod-cycle-gan} also contains two executable scripts -- \texttt{train.py} and \texttt{test.py}. The script \texttt{train.py} is used for training a CycleGAN and has 36 different flags. However, the script is mostly only a wrapper around instantiating various classes and running the method \texttt{train} of the class \texttt{CycleGAN}. Running the script with the help flag \texttt{-{}-helpfull} lists all the available flags and their short description. You can set up almost all of the parameters mentioned in the description of the public methods of exported classes.

The script \texttt{test.py} is used for testing the resulting network and has 9 flags. It is a wrapper around the static method \texttt{test\_one\_part} of the class \texttt{CycleGAN}. Running the script with the help flag \texttt{-{}-helpfull} lists all the available flags and their short description.

\section[\texttt{dat-unpacker}]{\texttt{dat-unpacker} -- C++ utility}

\texttt{dat-unpacker} is a small utility program based on ADTF Streaming library by Audi Electronics Venture GmbH. The reasoning for writing this utility program is to be able to unpack data obtained in ADTF DAT format and further process them. In order to build \texttt{dat-unpacker}, C+{}+ compiler, CMake\footnote{\url{https://cmake.org/}} in version at least 3.5, Boost\footnote{\url{https://www.boost.org/}} and ADTF Streaming library are needed. Binary copy of ADTF Streaming library is provided in the directory \texttt{code/external/adtf-streaminglib}.

The utility was written with Valeo dataset in mind, therefore a lot of features are hardcoded and specific to the data from Valeo dataset only. The utility takes a DAT file as an input, extracts information such as point clouds, timestamps, etc. from it and dumps the data on disk in a very crude format for further processing by Python.

This utility accepts four arguments:
\begin{description}
\descitem{\texttt{-i/--input-file [FILE\_NAME]} -- required} Input DAT file to read. This file needs to contain at least streams with names containing strings \texttt{"matrix"}, \texttt{"scan"} and \texttt{"3dod"}. The number of datablocks within the streams with the names \texttt{"matrix"} and \texttt{"scan"} needs to be the same. Furthermore, it is expected that each block of the stream \texttt{"scan"} will contain $4\times4\times n$ bytes, where every 16 bytes correspond to 4 float numbers indicating one point scanned by Velodyne LiDAR in XYZI format. All points within one data-block will be in the same coordinate frame, where position (0, 0, 0) corresponds to the center of the car, and will correspond to one revolution of LiDAR. Each block of the stream \texttt{"matrix"} will contain a string \texttt{"<matrix>[}$x$\texttt{]"} where $x$ is a string representation of 16 float numbers encoding a $4\times4$ matrix used to convert each corresponding block of stream \texttt{"scan"} into a {\em reference} coordinate frame. Stream \texttt{"3dod"} contains {\em one} datablock consisting of $4\times4\times m$ bytes with the same format as blocks from the stream \texttt{"scan"} with all the points transformed into one common reference frame and optionally filtered out according to some rule.

The input DAT file may contain additional streams which do not concern the \texttt{dat-unpacker} utility. The utility probably will not accept DAT files produced by other companies, unless the adhere to the requirements specified above.
\descitem{\texttt{-o/--output-dir [DIR\_PATH]} -- required} The directory in which to dump all the useful data. The directory will be created if it does not exist yet. There will be data numbered from 0 with three different extensions -- \texttt{.ts}, \texttt{.matrix} and \texttt{.pts}. All of them are only binary representations of the numeric data contained in the input DAT file. Files with the extension \texttt{.ts} have size of 8 bytes and it is one signed long integer corresponding to the timestamp of the block with microsecond resolution. Files with the extension \texttt{.matrix} have size of 128 bytes and it is 16 doubles corresponding to the transformation matrix. Files with the extension \texttt{.pts} have size of $4\times4\times n$ bytes and they correspond to one unmodified block from the stream \texttt{"scan"} of the input file.
\descitem{\texttt{-a/--all} -- optional} If this flag is specified, there will be one additional file in the output directory called \texttt{0000.dod} which contains all the points recorded within the datablock from the stream \texttt{"3dod"}.
\descitem{\texttt{-h}} Prints the simple help and exits.
\end{description}


\section[\texttt{data-processing}]{\texttt{data-processing} -- various Python modules and scripts}

Folder \texttt{data-processing} contains two Python modules and one Cython module as well as 4 scripts in a folder \texttt{scripts}. The creation of LiDAR-like dataset is split into two parts -- first we create unified ZIP files containing all the info we have (metadata such as camera position, rotation, timestamp, etc., point clouds and transformation matrix to one common coordinate frame) and then we create NumPy LiDAR-like data from these ZIP files by casting virtual rays into the point clouds.

\subsection{Module \texttt{zip\_processing}}
The module \texttt{zip\_processing} has 4 functions:
\begin{description}
\descitem{\texttt{rgb2gs}} Simple function converting RGB image (\texttt{rgb}) to grayscale {\em without} gamma correction.
\descitem{\texttt{depth\_to\_pcl}} Conversion of GTA depth images into point clouds. Takes depth image (\texttt{depth}), RGB image (\texttt{rgb}, for using grayscale value as intensity of the point in resulting point cloud), inversion of projection (\texttt{proji}) and view matrices (\texttt{viewi}) and bounding box (\texttt{bbox}) in which to convert the points. The points that are further in distance from the camera center than the limits specified by the bounding box will be thrown away.
\descitem{\texttt{make\_gta\_zip}} Creates one ZIP file from GTA data. It expects ID (\texttt{i}) of the GTA file, paths to json (\texttt{json\_file}) with metadata, depth image (\texttt{depth\_file}) and RGB image (\texttt{rgb\_file}), bounding box (\texttt{bbox}, with same semantics as \texttt{depth\_to\_pcl}) and two optional arguments \texttt{outputdir} (if \texttt{None}, no data will be saved) and \texttt{return\_data}.
\descitem{\texttt{make\_valeo\_zips}} Creates ZIP files from Valeo DAT files. Expects a DAT file (\texttt{datfile}), path to the binary of \texttt{dat-unpacker} (\texttt{binary}) and a directory in which to store the results (\texttt{outputdir}). It also has one optional argument (\texttt{remove}) specifying whether to remove temporary files created by \texttt{dat-unpacker} after processing them into one ZIP file. It creates one ZIP file for each revolution of LiDAR in the \texttt{outputdir}.
\end{description}

\subsection{Module \texttt{datapool}}
The module \texttt{datapool} contains two classes for manipulating ZIP files created by module \texttt{zip\_processing} and three functions for reading data from the ZIP file. The class \texttt{DataPool} keeps ZIP files in a cache and is primarily intended for Valeo dataset, since point cloud from one ZIP file corresponds to the full rotation of LiDAR. The constructor expects a list of ZIP files in a format produced by functions in module \texttt{zip\_processing}. The constructor will read only metadata from these ZIP files and fetches the data only when requested by method \texttt{load\_data}. This method returns a point cloud and car center at a particular timestamp. There is also a method \texttt{load\_rotmat} which returns a rotational matrix specifying the the angle between a ray in the direction (1, 0, 0) and heading of the car.

The class \texttt{GTADataPool} extends the class \texttt{DataPool} and serves the same purpose, only for GTA data. The reasoning for this is the fact that it is necessary to concatenate multiple point clouds to simulate a full rotation of LiDAR. The method \texttt{load\_full\_rot} fetches the point clouds at nearest timestamps, concatenates them together and interpolates the position of the car at particular timestamp.

The module also has functions \texttt{read\_pcl}, \texttt{read\_metadata} and \texttt{read\_both} for reading data from ZIP files in format produced by module \texttt{zip\_processing}. All of them expect a path to the ZIP file.

\subsection{Module \texttt{rays}}
Module rays is a Cython module, so before using it, it is necessary to compile the module. For a convenience, there is a simple Makefile provided which does the compilation. After that you can use it as any you would any other Python module. It has 4 public functions.

\begin{description}
\descitem{\texttt{gta\_cam\_rot}} Creates rotational matrix from two NumPy vectors of Euler angles. The first vector (\texttt{world\_rot}) corresponds to world rotation and second vector (\texttt{relative\_rot}) corresponds to relative rotation, since the camera can be rotated differently than the heading of the car. Third optional argument (\texttt{rads}) specifies, whether the angles are already in radians or in degrees.

\descitem{\texttt{interpolate\_lidar}} This function fills in missing values of the LiDAR-like data. This procedure is described more in detail in the section \ref{dataset}. First argument (\texttt{lidar\_data}) is a NumPy array of LiDAR-like data, second argument (\texttt{to\_fill}) specifies the minimal percentage of neighboring rays that has to be valid in order to fill in the missing value. Next argument (\texttt{mask\_size}) specifies the size of the neighborhood across which to interpolate missing values and last argument (\texttt{iters}) specifies how many times should the procedure be done. If there is no more values to fill (either all values are filled or no missing value has enough filled neighbors), then this method will do less iterations than prescribed by argument \texttt{iters}.

\descitem{\texttt{get\_lidar\_data}} This method computes the LiDAR-like data from an instance of either \texttt{DataPool} or \texttt{GTADataPool} classes at a given timestamp. First argument (\texttt{pool}) corresponds to the instance of the \texttt{DataPool} class, second argument (\texttt{timestamp}) corresponds to the timestamp at which to compute the data (double, in seconds, however with double precision), third argument (\texttt{lidar\_correction}) corresponds to the shift of the virtual center of the LiDAR if it is not located at the origin of the coordinate frame of the point cloud and could be set to \texttt{None}, if no correction is necessary. The last argument (\texttt{allowance}) corresponds to the maximal ratio of the distance of the point to the ray and the length of the ray itself in order to be considered valid. Note, that even though the function is written in quite an optimized fashion, it still takes large amount of time on a dense point clouds because it needs to cast $64\times2084$ virtual rays and find the nearest point in the point cloud from them. It takes about three to four minutes on a GTA dataset for {\em one} element of LiDAR like data. It takes significantly less time on Valeo dataset since it is much sparser.

\descitem{\texttt{reconstruct\_pcl}} This method creates point cloud corresponding to the instance of LiDAR-like data. It takes one argument (\texttt{lidar\_data}) and returns point cloud in the form of NumPy array in the shape of $4\times n$ where n is a number of valid rays. The returned point cloud is in XYZI format.
\end{description}

\subsection{\texttt{data-processing} scripts}
There are three scripts for processing data to create a dataset and one script to get the viewable data from finished experiments. The processing scripts are \texttt{gta-lidar.py}, \texttt{gta-zip.py} and \texttt{valeo-lidar.py} and all of these take three arguments -- input folder, output folder and optionally third argument specifying the number of threads to use. If the third argument is not set, the script will use half of the available CPUs. The scripts are mostly wrappers around the functions in the modules in \texttt{data-processing folder}.

The last script called \texttt{process-output.py} takes two arguments -- first argument corresponds to the folder where two files with the names \texttt{gta2valeo.npz} and \texttt{valeo2gta.npz} are located and second argument optionally specifies the number of samples to process. If it is not set, then the number of samples is assumed to be 100. It creates two folders within the input folder called \texttt{gta2valeo} and \texttt{valeo2gta} each of them containing 6 files for each sample processed. The files are depth and intensity images (saved as $64\times2084$ grayscale PNG images) and point cloud stored as a text file (for viewing by for example CloudCompare software\footnote{\url{http://www.danielgm.net/cc}}) with each row corresponding to one point in the point cloud. The files are stored as original input data to the CycleGAN network and their transformed counterparts. The resulting filenames are therefore \texttt{\%03d.\{depth,inten\}.\{orig,conv\}.png} and \texttt{\%03d.pcl.\{orig,conv\}.txt}, where \texttt{\%03d} is ID number of the sample within the processed files.
